C=NULL
for(i in 1:length(Forwards2)){
volatility=VolImpl2[i,3]
maturity=as.numeric(gsub("M","",names(Forwards2)[i]))/12
underlying=Forwards2[i]
C=c(C,optim(par=Forwards2[i],fn=Optimizar,method="L-BFGS-B",lower=1000,upper=10000,maturity=maturity,volatility=volatility,underlying=underlying,delta=0.1,control=list(parscale=100))$par)
}
A=cbind(t(Forwards2),t(B),t(C))
print(y)
return(A)
})
StrikesPut=t(StrikesPut)
colnames(StrikesPut)=paste(sort(rep(c("ATM","25D","10D"),6),decreasing=T),colnames(Forwards),sep=" ")
rownames(StrikesPut)=as.character(vol[,1])
tail((StrikesPut))
#####################################################################################################
##################################### Superficie de volatilidad #####################################
#####################################################################################################
Fecha=as.Date("2019-09-30") # as.Date("2019-07-31") # vol[nrow(vol),1]
Strikes_superficie=t(t(StrikesCall[as.character(Fecha),]))
Strikes_superficie=rbind(Strikes_superficie,t(t(StrikesPut[as.character(Fecha),-grep("ATM",colnames(StrikesPut))])))
IndicadorFila=max(which(vol[,1]<=Fecha))
VolImpl=unlist(cbind(vol[IndicadorFila,-1],volput[IndicadorFila,-c(1,1+grep("ATM",colnames(StrikesPut)))]))
VolImpl=(t(VolImpl))
Spot=Spot[as.character(Fecha),1]
# Time
xx = (rep(c(1,2,3,6,9,12),5)/12)
# Strike
yy = c(Strikes_superficie)
# ImpVol
zz = c(VolImpl)/100
#########
b1 = gam(zz ~ s(xx,yy,k=15), familiy=gaussian())
yss = seq(min(Strikes_superficie), max(Strikes_superficie), length.out=250)
xss = seq(0,1,length.out=250)
gg = expand.grid(xx=xss,yy=yss)
rr = predict.gam(b1,newdata=gg )
gg2 = cbind(gg,rr)
mama = xtabs(rr~xx+yy, data=gg2)
obj11 = list( x=  sort(unique(gg2[,2])),y=sort(unique(gg2[,1])),z=t(mama))
image.plot(obj11,ylab="Expiración (años)", xlab="Strike", main="Superficie de volatilidad")
points(yy,xx, pch=18, cex=0.75)
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
shiny::runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp()
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
grep("hola",c("hola$1","1$hola","hola$2"))
grep("hola",c("hola$1","1$hola","hola$2"))
grep("hola$",c("hola$1","1$hola","hola$2"))
x=runif(1000,-10,10)
y=x^2
cor(x,y,method = "kendall")
cor(x,y,method = "spearman")
cor(x,y,method = "pearson")
install_github("ProcessMiner/nlcor")
library(devtools)
install.packages(devtools)
install.packages("devtools")
library(devtools)
install_github("ProcessMiner/nlcor")
library(nlcor)
nlcor(x,y)
modelito=nlcor(x,y)
print(modelito$cor.plot)
modelito=nlcor(x,y,plt = T)
print(modelito$cor.plot)
library(ggplot2)
modelito=nlcor(x,y,plt = T)
print(modelito$cor.plot)
modelito=nlcor(x,y,refine = 5,plt = T)
print(modelito$cor.plot)
x=runif(1000,-10,10)
y=x^2
cor(x,y,method = "pearson")
cor.test(x,y)
cor(x,y,method = "pearson")
nlcor(x,y,refine = 5,plt = T)$cor.estimate
modelito=nlcor(x,y,refine = 1,plt = T)
print(modelito$cor.plot)
print(modelito$cor.plot)
cor(x,y,method = "pearson")
cor(x,y,method = "kendall")
cor(x,y,method = "pearson")
nlcor(x,y,plt = T)$cor.estimate
x=runif(1000,-10,10)
y=x^2
x_unif=punif(x,min = -10, max=10)
x_unif
hist(punif(x,)
hist(punif(y))
hist((y))
x=runif(1000,-10,10)
y=runif(1000,-10,10)
x=mvtnorm::rmvnorm(1000,c(0,0),sigma = matrix(c(1,0.5,0.5,1),ncol=2))
y=x[,2]
x=x[,1]
plot(x,y)
x_unif=pnorm(x,mean =  0 ,sd = 1)
y_unif=pnorm(y,mean =  0 ,sd = 1)
plot(x_unif,y_unif)
plot(x_unif,y_unif)
cor(x_unif,y_unif)
??copula
install.packages(c("BLCOP", "fPortfolio", "LowRankQP", "pastecs"))
install.packages(c("copula", "fitdistrplus", "moments", "nortest"))
library(copula)
gC.f <- normalCopula(dim=2)
gcF.ml  <- fitCopula(gC.f, cbind(x_unif,y_unif), method="ml")
coef.t=summary(gcF.ml)$coefficients[,1]
tC.f.post <- tCopula(param=coef.t,dim=ncol(rets_aux))
tC.f.post <- tCopula(param=coef.t,dim=2)
pvars<-rCopula(n=nSim,tC.f.post)
pvars<-rCopula(n=1000,tC.f.post)
plot(pvars)
DatosFin=cbind(pnorm(pvars[,1],mean =  0 ,sd = 1),pnorm(pvars[,2],mean =  0 ,sd = 1))
plot(DatosFin)
DatosFin=cbind(qnorm(pvars[,1],mean =  0 ,sd = 1),qnorm(pvars[,2],mean =  0 ,sd = 1))
plot(DatosFin)
plot(cbind(x,y))
plot(DatosFin)
par(new=T)
plot(cbind(x,y),col="blue")
plot(DatosFin,xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
par(new=T)
plot(cbind(x,y),col="blue",xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
DatosFin=cbind(qnorm(pvars[,1],mean =  0 ,sd = 1),qnorm(pvars[,2],mean =  0 ,sd = 1))
plot(DatosFin,col="blue",xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
par(new=T)
plot(cbind(x,y),xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
plot(cbind(x,y),xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
par(new=T)
plot(DatosFin,col="blue",xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
plot(pvars)
plot(pvars,xlab="X sim uniforme",ylab="Y sim uniforme")
plot(pvars,xlab="X sim uniforme",ylab="Y sim uniforme",col="blue")
CalcularMejor=function(Retornosaux,indicesTrain=NULL,j=NULL){
#######----------- Paso 1: Estimación de Distribuciones ----------- ########
Retornosaux = Retornos
#### --------- Pruebas de distancia de Kolmogorov-Smirnov ------- #######
######### ---------- Se crea una Matriz con 6 columnas (distribuciones)
######### ---------- 10 filas (Acciones)
Testkol=as.data.frame(matrix(0,ncol=5,nrow=ncol(Retornosaux)))
####### ------------ Muestra de entrenamiento/ Muestra Prueba --------- #######
porcentajeTrain=0.5
indicesTrain_aux=sample(1:(nrow(Retornosaux)),porcentajeTrain*nrow(Retornosaux))
######### ------------- Separacion entre muestra de entrenamiento y muestra de prueba ------- ########
indicesTest_aux=(1:nrow(Retornosaux))[-indicesTrain_aux]
rownames(Testkol)=colnames(Retornosaux)
#####---------- Distribuciones a estimar -------------- #######
colnames(Testkol)=c("Normal","Logistica","Uniforme","Hiperbolica","Ganador")
##### ---------- Fin construcción tabla ------ #########
retsAcc = Retornosaux
for (i in 1:ncol(Retornosaux)){
x=retsAcc[,i]
#   descdist(c(x),discrete=F)
####### --------- Ajustar un modelo Arima para definir en un GARCH--------- #####
ARMA=auto.arima(x)
AR=length(grep("ar",names(ARMA$coef)))
MA=length(grep("ma",names(ARMA$coef)))
if(AR+MA==0){
AR=1
}
##### -------- Definir el número de grados de ARCH a partir de los residuales -------- ######
## A a partir de los residuales al cuadrado se determina el grado del modelo ARCH.
#### --------- Auto
ARCH=auto.arima(ARMA$residuals^2)$coef
AR_ARCH=length(grep("ar",names(ARCH)))
MA_ARCH=length(grep("ma",names(ARCH)))
####### --------- Especificación GARCH ------- ##########
Especificacion_garch=ugarchspec(mean.model = list(armaOrder = c(AR,MA)),variance.model = list(garchOrder = c(max(1,AR_ARCH),MA_ARCH)), distribution.model = "norm")
####### ---------- Ajustar el modelo ------- ######
Garch_ajustado = ugarchfit(Especificacion_garch, data = x,solver="gosolnp")
Residuales_garch = residuals(Garch_ajustado)
xyz=as.numeric(Residuales_garch)
set.seed(124)
indicesTrain=NULL
############# --------- Definicion de entrenamiento/prueba -----#######
indicesTrain=sample(1:(length(xyz)),0.5*length(xyz))
indicesTest=(1:length(xyz))[-indicesTrain]
################ -------------- Normal: (Prueba+Entrenamiento)/2 --------------#########
######### ----------- Sobre la muestra de entrenamiento --------- #########
param_norm=try(unlist(fitdistrplus::fitdist(c(xyz[indicesTrain]),"norm")[1]),silent=T)
if(class(param_norm)=="try-error"){
Testkol[i,"Normal"]=Inf
} else {
names(param_norm)=gsub("estimate.","",names(param_norm))
######## --------- Kolmogorov-Smirnov Tests --------- #########3
Testkol[i,"Normal"]=ks.test(x=xyz[indicesTest],y = "pnorm",mean = param_norm[1], sd = param_norm[2])[[1]]
}
######### ----------- Sobre la muestra de prueba --------- #########
param_norm=try(unlist(fitdistrplus::fitdist(c(xyz[-indicesTrain]),"norm")[1]),silent=T)
if(class(param_norm)=="try-error"){
Testkol[i,"Normal"]=Inf
} else {
names(param_norm)=gsub("estimate.","",names(param_norm))
#### -------- Promedio ------ ####
Testkol[i,"Normal"]=(Testkol[i,"Normal"]+ks.test(xyz[-indicesTest],"pnorm",mean = param_norm[1], sd = param_norm[2])[[1]])/2
}
################ -------------- Uniforme: (Prueba+Entrenamiento)/2 --------------#########
######### ----------- Sobre la muestra de entrenamiento --------- #########
param_unif=try(unlist(fitdistrplus::fitdist(c(x[indicesTrain]),"unif")[1]),silent=T)
if(class(param_unif)=="try-error"){
Testkol[i,"Uniforme"] = Inf
} else {
names(param_unif)=gsub("estimate.","",names(param_unif))
Testkol[i,"Uniforme"] = ks.test(xyz[-indicesTrain],"punif",min=param_unif["min"],max=param_unif["max"])[[1]]
}
######### ----------- Sobre la muestra de prueba --------- #########
param_unif=try(unlist(fitdistrplus::fitdist(c(x[-indicesTrain]),"unif")[1]),silent=T)
if(class(param_unif)=="try-error"){
Testkol[i,"Uniforme"]=Inf
} else {
names(param_unif)=gsub("estimate.","",names(param_unif))
#### -------- Promedio ------ ####
Testkol[i,"Uniforme"]=(Testkol[i,"Uniforme"]+ks.test(xyz[indicesTrain],"punif",min=param_unif["min"],max=param_unif["max"])[[1]])/2
}
################ -------------- Logistica: (Prueba+Entrenamiento)/2 --------------#########
######### ----------- Sobre la muestra de entrenamiento --------- #########
param_logistic=try(unlist(fitdistrplus::fitdist(c(xyz[indicesTrain]),"logis")[1]),silent=T)
if (class(param_logistic)=="try-error"){
Testkol[i,"Logistica"]= Inf
} else {
names(param_logistic)=gsub("estimate.","",names(param_logistic))
Testkol[i,"Logistica"]=ks.test(xyz[-indicesTrain],"plogis",location = param_logistic[1], scale = param_logistic[2])[[1]]
}
######### ----------- Sobre la muestra de prueba --------- #########
param_logistic=try(unlist(fitdistrplus::fitdist(c(xyz[-indicesTrain]),"logis")[1]),silent=T)
if(class(param_logistic)=="try-error"){
Testkol[i,"Logistica"]=Inf
} else {
names(param_logistic)=gsub("estimate.","",names(param_logistic))
Testkol[i,"Logistica"]=(Testkol[i,"Logistica"]+ks.test(xyz[indicesTrain],"plogis",location = param_logistic[1], scale = param_logistic[2])[[1]])/2
}
################ -------------- Hiperbolica: (Prueba+Entrenamiento)/2 --------------#########
param_hyper=try(unlist(ghFit(c(xyz[indicesTrain]),trace=F,doplot=F)@fit$estimate),silent=T)
######### ----------- Sobre la muestra de entrenamiento --------- #########
if(class(param_hyper)=="try-error"){
Testkol[i,"Hiperbolica"]=Inf
} else {
names(param_hyper)=gsub("estimate.","",names(param_hyper))
Testkol[i,"Hiperbolica"]=ks.test(xyz[-indicesTrain],"pgh",alpha=param_hyper["alpha"],beta=param_hyper["beta"],delta=param_hyper["delta"],mu=param_hyper["mu"],lambda=param_hyper["lambda"])[[1]]
}
######### ----------- Sobre la muestra de prueba --------- #########
param_hyper=try(unlist(ghFit(c(xyz[-indicesTrain]),trace=F,doplot=F)@fit$estimate),silent=T)
if(class(param_hyper)=="try-error"){
Testkol[i,"Hiperbolica"]= Inf
} else {
names(param_hyper)=gsub("estimate.","",names(param_hyper))
Testkol[i,"Hiperbolica"]=(Testkol[i,"Hiperbolica"]+ks.test(xyz[indicesTrain],"pgh",alpha=param_hyper["alpha"],beta=param_hyper["beta"],delta=param_hyper["delta"],mu=param_hyper["mu"],lambda=param_hyper["lambda"])[[1]])/2
}
print(i)
}
###### ----------- Las mejores marginales Independiente -------- #####
Testkol[,"Ganador"]=colnames(Testkol)[apply(Testkol[,-ncol(Testkol)],1,which.min)]
# Testkol=Testkol[,-3]
Testkol[,1:5]=round(Testkol[,1:5],4)
Testkol[Testkol==Inf]="No Convergió"
}
###### --------------------- Ejercicio: Optimizacion de portafolios ----------------- ############
####### ----------- Limpiar ambiente ------- ######
rm(list = ls())
options(scipen = 10000000)
##### --------- Path: automatico  --------- #####
path <<- gsub(rstudioapi::getActiveDocumentContext()$path,pattern = "/Script.+",replacement = "")
setwd(paste0(path))
##### -------- librerias ------- ######
librerias <- c("readxl","ggplot2","scales",'timeSeries','timeSeries','forecast','rugarch','fBasics','moments','tseries','PortfolioAnalytics','dplyr','zoo','nleqslv')
###### ----- Instalacion liberarias ------ ####
if(length(setdiff(librerias, rownames(installed.packages()))) > 0){
install.packages(setdiff(librerias, rownames(installed.packages())))}
invisible(sapply(librerias, require, character.only = TRUE,quietly = TRUE))
source('Utilities.R',)
##### --------- Paso 1: Cargar datos ------ #####
TESCOP = read_excel('Datos/TESCOP.xlsx')
TESCOP= as.data.frame(TESCOP)
############ ---------- Ejemplo de la construcción de un índice entre dos TES -------- ######
####### ---------- Funcion TES ----------- ######
rownames(TESCOP) = as.Date(TESCOP[,1])
TESCOP = TESCOP[,-1]
colnames(TESCOP) = gsub(x = colnames(TESCOP),pattern = 'TESCOP_',replacement = '')
##### ------- Se toman los Meses y se pasan a numero ---- #####
colnames(TESCOP)[grep(colnames(TESCOP),pattern = 'M')] = as.numeric(gsub(colnames(TESCOP)[grep(colnames(TESCOP),pattern = 'M')],pattern = 'M',replacement = ''))/12
##### ------- Se toman los años y se pasan a numero---- #####
colnames(TESCOP)[grep(colnames(TESCOP),pattern = 'Y')] = as.numeric(gsub(colnames(TESCOP)[grep(colnames(TESCOP),pattern = 'Y')],pattern = 'Y',replacement = ''))
######## ---- Interpolacion de un nodo de 10 - semana ------ ###
Interpolacion = apply(TESCOP, 1, function(z){approx(x = as.numeric(colnames(TESCOP)),y = as.numeric(z),xout = ((365*10-7)/365))$y})
TESCOP[,'9.98'] = Interpolacion
############ -------- Semanalizar: Cogiendo ---------- ##########
## Vamos a generar la serie semanal ##
DatosSem=seq(as.Date(rownames(TESCOP)[1]),as.Date(tail(rownames(TESCOP),1)),by = "week")
## En caso de festivos, tomamos el dia mas cercano.
DatosSem=sapply(DatosSem,function(x){which.min(abs(as.Date(rownames(TESCOP))-x))})
######## --------- Consolidar DataFrame: Resultados -------- ######
TESCOP = TESCOP[c(DatosSem),]
Resultados = data.frame('Semana'=c(1:dim(TESCOP)[1]),'Tasa1'=TESCOP[,'10'],'Tasa2'=TESCOP[,'9.98'],'TES1'=0,'TES2'=0)
####### ------- Rendimientos ------ ######
for (j in c(1:dim(Resultados)[1])) {
##### ---- TES 1 ---- ###
Resultados[j,"TES1"] = 1/(1+(Resultados[j,"Tasa1"]/100))^(10)
##### ---- TES 2 ---- ###
Resultados[j,"TES2"] = 1/(1+(Resultados[j,"Tasa2"]/100))^((365*10-7)/365)
}
TESS = cbind(Resultados[-nrow(Resultados),"TES1"],Resultados[-1,"TES2"])
Resultados$Acum = c(1,cumprod(TESS[,2]/TESS[,1]))
returns(Resultados)
dim(Resultados)
head(Resultados)
source('C:/Users/USUARIO/Dropbox (Quantil)/Uniandes Portafolio/Clases/Clase 7 - Ejercicio/Ejercicios/CalcularMejor.R', encoding = 'UTF-8')
source('C:/Users/USUARIO/Dropbox (Quantil)/Uniandes Portafolio/Clases/Clase 7 - Ejercicio/Ejercicios/Utilities.R', encoding = 'UTF-8')
###### --------------------- Ejercicio 1: ----------------- ############
####### ----------- Limpiar ambiente ------- ######
rm(list = ls())
##### --------- Path: automatico  --------- #####
path <<- gsub(rstudioapi::getActiveDocumentContext()$path,pattern = "/Ejercicio 1.+",replacement = "")
setwd(paste0(path,'/Ejercicio 1'))
##### -------- librerias ------- ######
librerias <- c("readxl","ggplot2","scales",'timeSeries','timeSeries','forecast','rugarch','fBasics','zoo','moments','tseries','fPortfolio','data.table','kernlab','abind','BLCOP','xts')
###### ----- Instalacion liberarias ------ ####
if(length(setdiff(librerias, rownames(installed.packages()))) > 0){
install.packages(setdiff(librerias, rownames(installed.packages())))}
invisible(sapply(librerias, require, character.only = TRUE,quietly = TRUE))
Graficar_simulaciones  = function(mat,title,hist=NULL,plotear=F,quitarCeros=0,leyenda_x,leyenda_y,Fecha_inicial = "2011-09-01"){
## INPUTS
## 1. mat: matriz con las simulaciones por columnas
## 2. hist: vector con la historia de la variable simulada
## 3. quitarCeros: numero de ceros a quitar
## 4. plot: Si se desea plotear o no
mat=t(mat)
medias = colMeans(mat)
data = data.frame(media = medias)
upper_seq = seq(70,95,by = 5)/100
int=t(apply(mat,2,quantile,probs=upper_seq))
data=cbind(data,t(apply(mat,2,quantile,probs=c(1-upper_seq,upper_seq))))
colnames(data) = c("media","min70","min75","min80","min85","min90","min95","max70","max75","max80","max85","max90","max95")
if(!is.null(hist)){
hist=matrix(rep(hist,ncol(data)),ncol = ncol(data))
colnames(hist)=colnames(data)
data=rbind(hist,data)
data=data/10^quitarCeros
}
data = cbind(seq(as.Date(Fecha_inicial),length.out = length(rownames(data)),by="month"),data)
colnames(data) = c("Fecha",colnames(data)[-1])
plot1 = ggplot(data=data)+
geom_ribbon(aes(x=Fecha,ymin=min95,ymax=max95),alpha=0.3,fill="#67001f") +
geom_ribbon(aes(x=Fecha,ymin=min90,ymax=max90),alpha=0.4,fill="#b2182b") +
geom_ribbon(aes(x=Fecha,ymin=min85,ymax=max85),alpha=0.5,fill="#d6604d") +
geom_ribbon(aes(x=Fecha,ymin=min80,ymax=max80),alpha=0.6,fill="#878787") +
geom_ribbon(aes(x=Fecha,ymin=min75,ymax=max75),alpha=0.7,fill="#4d4d4d") +
geom_line(aes(x=Fecha,y=min95),col="#4575b4",size=1.5,alpha =0.5) +
geom_line(aes(x=Fecha,y=max95),col="#4575b4",size=1.5,alpha =0.5) +
geom_line(aes(x=Fecha,y=media),col="#4575b4",size=1.5) +
theme(legend.position="none") + labs(title = title)+
theme_bw()+ theme(legend.background = element_rect(fill="white", size=2.5, linetype="solid"),legend.title = element_text(colour="black", size=12, face="bold"),axis.text.x=element_text(angle=0, hjust=1),legend.text = element_text(colour="black", size=15, face="bold"),panel.grid.major = element_blank(), panel.border = element_blank(), plot.title = element_text(hjust = 1),axis.text=element_text(size=25,face="bold"),axis.title=element_text(size=25,face="bold"),legend.position = "top")+labs(title=title)+labs(x = leyenda_x, y = leyenda_y) +scale_x_date(date_breaks = "14 month", date_labels =  "%b %y")+scale_y_continuous(labels = comma)
if(plotear){print(plot1)}
return(plot1)
}
matrizCovHorizonte = function(prior,periodo){
# Inputs
# prior: lista con retornos esperados y matriz de varianza covarianza
# Output:
# matCov: matriz de varianza covarianza al horizonte escogido en periodo.
mu = prior$mu
sigma = prior$sigma
matCov = matrix(0,nrow(sigma),ncol(sigma))
nAcc = nrow(sigma)
for(i in 1:nAcc){
for(j in 1:nAcc){
matCov[i,j] = (1+mu[i]+mu[j]+sigma[i,j]+mu[i]*mu[j])^periodo - (1+mu[i])^periodo*(1+mu[j])^periodo
}
}
rownames(matCov)=rownames(sigma)
colnames(matCov)=colnames(sigma)
return(matCov)
}
############## -------------- 1 Cargar informacion TESCOP y TESIBR --------------- #################
DatosMercado = as.data.frame(read_excel('Datos/Datos.xlsx'))
rownames(DatosMercado) = DatosMercado[,1]
DatosMercado = DatosMercado[,-1]
#######----- Crear indice IBR ------ #####
tasaBR=t(t(DatosMercado[,c("IBR")]))/100
rownames(tasaBR)=rownames(DatosMercado)
DatosMercado=DatosMercado[,!colnames(DatosMercado)%in%c("IBR")]
tasaBR=(1+tasaBR)^(1/250)-1
# Calcular precio del activo libre de riesgo (arranca en 100, rendimiento igual a tasa BanRep)
nomAccs = colnames(DatosMercado)
nomActivo="IBR"
DatosMercado = cbind(DatosMercado,rep(100,nrow(DatosMercado)))
names(DatosMercado)=c(nomAccs,nomActivo)
DatosMercado[,"IBR"]=cumprod(1+tasaBR)
fechasAccs = as.Date(rownames(DatosMercado))
###### ------------ Retornos ------------ #######
Datos=xts(DatosMercado,order.by=(as.Date(rownames(DatosMercado))))
RetornosMercado = apply(Datos, 2, function(x){returns(x, method='simple')})[-1,]
#### ----- Portafolio S&P ficticio: Mix CEMBI 50%  ---- ####
RetornosMercado[,"S&P"]= as.matrix((RetornosMercado[,"CEMBI"]*0.5) + (RetornosMercado[,"S&P"]*0.5))
### --- Eliminarlo --- ####
RetornosMercado=RetornosMercado[,!colnames(RetornosMercado)%in%"CEMBI"]
### ---  2. Suavizamiento exponencial ------ ####
SuavizamientoExponencial = function(X){
retornos = X
lambda= 0.086
TiempoFin=nrow(X)
##Pesos
w=matrix((1-lambda)^(seq(TiempoFin-1,0)),ncol=TiempoFin)
##Mu
mu=lambda/(1-(1-lambda)^TiempoFin)*w%*%X
mu=matrix(mu,ncol=1)
##Sigma
w=matrix((1-lambda)^(seq(TiempoFin-1,0)),ncol=TiempoFin)
w=matrix(rep(w,ncol(X)), ncol=ncol(X))
mu=matrix(rep(mu,ncol(t(retornos))),ncol=ncol(t(retornos)))
sigma=lambda/(1-(1-lambda)^TiempoFin)*(t(w*t((t(retornos)-mu)))%*%t((t(retornos)-mu)))
mu=mu[,1]
names(mu)=colnames(X)
##
w=matrix((1-lambda)^(seq(TiempoFin-1,0)),ncol=TiempoFin)
w=matrix(rep(w,ncol(X)), ncol=ncol(X))
mu=matrix(rep(mu,ncol(t(retornos))),ncol=ncol(t(retornos)))
sigma=lambda/(1-(1-lambda)^TiempoFin)*(t(w*t((t(retornos)-mu)))%*%t((t(retornos)-mu)))
mu=mu[,1]
names(mu)=colnames(X)
return(list(mu=mu,sigma=sigma))
}
############## -------------- Calibrar VARCOV--------------- #################
Resultados_estimacion = SuavizamientoExponencial(X = RetornosMercado)
Mu = Resultados_estimacion$mu
Sigma = Resultados_estimacion$sigma
Prior=list(mu=Mu,sigma=Sigma)
#### ------- Proyeccion ----- ######
horizonte = 182
Sigma=matrizCovHorizonte(prior=Prior,horizonte)
Mu=(1+Mu)^horizonte-1
###### ----------------- Views --------- ######
ViewsTot = as.data.frame(read_excel('Datos/Analistas.xlsx'))
#### ---- Acotar las columnas ----- #####
Views = ViewsTot[,c("Fecha","Activo","Retorno Esperado","Confianza")]
Views = data.frame(Mercado = Views[,'Activo'],Views_ret = Views[,"Retorno Esperado"],Views_conf = Views[,"Confianza"])
#### ---- Varianza ---- ####
Views[,"Views_conf"]=Views[,"Views_conf"]^2
Ret_View = Views
###### ---------- Matriz de Pick ---------- ######
# Transformacion matricial de los views:
Pick=diag(ncol(RetornosMercado))
colnames(Pick)=colnames(RetornosMercado)
rownames(Pick)=colnames(RetornosMercado)
Pick=rbind(Pick[match(Ret_View[,1],colnames(Pick)),])
#### ------- Views ----- ####
Views=BLViews(P=Pick,q=c(Ret_View[,"Views_ret"]), confidence=c(1/(Ret_View[,"Views_conf"])),assetNames=colnames(RetornosMercado))
#### ------ TAU desviavion de mu ------ #####
tau = 1/250
MarketPosterior=posteriorEst(views=Views,sigma=Sigma,mu=Mu,tau=tau)
#### ------ Sigma incorporando views ------ #####
Sigma = MarketPosterior@posteriorCovar
#### ------ Mu incorporando views ------ #####
Mu = MarketPosterior@posteriorMean
densityPlots(MarketPosterior)
############## -------------- Optimizacion de portafolio--------------- #################
X = (RetornosMercado)
## ---- Caja de restricciones --- ####
caja=cbind(rep(0,ncol(X)),rep(0.4,ncol(X)))
portfolioOptimQP = function(sigma,mu,Rbar,caja="no",A_sects=NULL,lims_sects=NULL){
## INPUTS:
# 1. sigma: matriz var-covar de las variables
# 2. mu: Retornos de las variables
# 3. Rbar: es el minimo retorno esperado
# 4. caja: Hay restricciones de caja? opciones: "no" o una matriz con las restricciones de caja
# 5. A_sets: matriz con las restricciones por sector ( nRestriccionesSectoriale x nAcciones)
# 6. lims_sects: Vector con los limites sectoriales correspondientes a A_sects
## OUTPUTS:
# 1. w: vector de pesos
Nvar = length(mu)
if(caja!="no" & is.null(A_sects)){ #Caso con restriccion de caja, sin restricciones sectoriales (Se puede usar LowRankQP)
#   # Solucion LowRankQP (FUNCIONA BIEN, la condicion Ax es de IGUALDAD) (OJO limite inferior es cero!!!)
#    Vmat = 2*sigma
#    Amat = t(cbind(rep(1,Nvar),mu))
#    dvec = t(0*mu)
#    bvec = c(1,Rbar)
#    uvec = caja[,2]
#    sol = LowRankQP(Vmat,dvec,Amat,bvec,uvec,method="LU",verbose=FALSE,niter=200)$alpha
# Solucion kernlab  (FUNCIONA BIEN, no optimiza en los dos extremos de la forntera!!!!!)
c = t(0*mu)
H = 2*sigma
A = rbind(rep(1,Nvar),mu)
b = c(1,Rbar)
l=(caja[,1])
u = (caja[,2])
r= c(0,0)                                    #verb=1 hace que se muestre la informacion de la convergencia
sol = try(ipop(c, H, A, b, l, u, r, sigf = 6, maxiter = 1000, margin = 0.005, bound = 10,verb = 0),silent=TRUE)
if(class(sol)=="try-error"){ sol=rep(NA,Nvar) }
else{ sol=sol@primal }
}
if(caja!="no" & !is.null(A_sects)){ #Caso con restriccion de caja, sin restricciones sectoriales (toca usar kernlab)
# Solucion kernlab  (FUNCIONA BIEN, no optimiza en los dos extremos de la forntera!!!!!)
c = t(0*mu)
H = 2*sigma
A = rbind(rep(1,Nvar),mu,A_sects)
b = c(1,Rbar,as.numeric(lims_sects[1,]))
l=(caja[,1])
u = (caja[,2])
r= c(0,0,as.numeric(lims_sects[2,]-lims_sects[1,]))                                    #verb=1 hace que se muestre la informacion de la convergencia
sol = try(ipop(c, H, A, b, l, u, r, sigf = 7, maxiter = 400, margin = 0.05, bound = 10,verb = 0),silent=TRUE)
if(class(sol)=="try-error"){ sol=rep(NA,Nvar) }
else{ sol=sol@primal }
}
return( sol )
}
######## ---------- Grilla de retornos de la frontera ---------- #######
Rbar=seq(min(Mu),max(Mu),length.out=100)
path
