for(j in 1:nrow(TasasHistoricas)){
FechaAnalisis=as.Date(rownames(TasasHistoricas)[j])
# calculamos las fechas de pago para la fecha de analisis
SecuenciasPagos=list()
Pagos=list()
TES[,3]=unlist(c(TasasHistoricas[j,]))
for(i in 1:nrow(TES[-1,])){
SecuenciasPagos[[i]]=seq(as.Date(paste0("2019-",month(TES[i+1,2]),"-",day(TES[i+1,2]))),as.Date(TES[i+1,2]),by="year")
SecuenciasPagos[[i]]=SecuenciasPagos[[i]][SecuenciasPagos[[i]]>FechaAnalisis]
}
for(i in 1:nrow(TES[-1,])){
Pagos[[i]]=rep(TES[i+1,1],length(SecuenciasPagos[[i]]))
Pagos[[i]][length(Pagos[[i]])]=Pagos[[i]][length(Pagos[[i]])]+1
}
# Calculamos el precio sucio usando la TIR
PS=list()
for(i in 1:nrow(TES[-1,])){
PS[[i]]=sum(Pagos[[i]]/(1+TES[i+1,3])^as.numeric((SecuenciasPagos[[i]]-FechaAnalisis)/365))
}
# Con el precio sucio, construimos las curvas.
Curva=NULL
FuncionTasa=function(Pagos_i,Fechas,FechaHoy,VP,CurvaAct,NodoFin){
Curva=c(CurvaAct,NodoFin)
names(Curva)=c(names(CurvaAct),(Fechas[length(Fechas)]-FechaHoy)/365)
TasasPagos=approx(x=as.numeric(names(Curva)),y=Curva,xout = as.numeric((Fechas-FechaHoy-0.0001)/365))$y
return(abs(sum(Pagos_i/(1+TasasPagos)^as.numeric((Fechas-FechaHoy)/365))-VP))
}
CurvaAct=TES[1,3]
names(CurvaAct)="0"
for(i in 1:nrow(TES[-1,])){
Fechas=SecuenciasPagos[[i]]
Pagos_i=Pagos[[i]]
FechaHoy=FechaAnalisis
VP=PS[[i]]
NodoFin=optim(par=TES[i+1,3],fn = FuncionTasa,method="L-BFGS-B",lower=0,upper = 1,Pagos_i=Pagos_i,Fechas=Fechas,FechaHoy=FechaHoy,VP=VP,CurvaAct=CurvaAct)
CurvaAct=c(CurvaAct,NodoFin$par)
names(CurvaAct)=c(names(CurvaAct)[-length(CurvaAct)],(Fechas[length(Fechas)]-FechaHoy)/365)
}
CurvaTot=rbind(CurvaTot,approx(x=as.numeric(names(CurvaAct)),y=CurvaAct,xout = c(0:15))$y)
}
rownames(CurvaTot)=rownames(TasasHistoricas)
CurvaTot=timeSeries(CurvaTot,charvec = as.Date(rownames(CurvaTot)))
colnames(CurvaTot)=c(paste0("Año",c(0:15)))
CurvaDiff=diff(CurvaTot)[-1,]
Prin_Comp=prcomp(na.omit(CurvaDiff))
summary(Prin_Comp)
barplot(Prin_Comp$sdev)
Total=sum(Prin_Comp$sdev^2)
Percentage=cumsum(Prin_Comp$sdev^2/Total)
NumCom=min(which(Percentage>=0.95))
Weights=Prin_Comp$rotation[,1:NumCom]
Componentes=(Prin_Comp$x)[,1:NumCom]
dim(Componentes)
d <- data.frame(Componentes[complete.cases(Componentes),])
d <- xts(d, order.by=as.Date(rownames(d)))
library(bizdays)
install.packages("bizdays")
library(bizdays)
bizdays(as.Date("2000-01-01",Sys.Date()))
bizdays(as.Date("2000-01-01"),Sys.Date())
bizdays.options$get("default.calendar"))
bizdays.options$get("default.calendar")
load("C:/Users/USUARIO/Downloads/laborales.Rdata")
wdNY
wdNY2
tail(wdNY2)
sum(!wdBOG%in%wdBOG2)
source('~/.active-rstudio-document', echo=TRUE)
shiny::runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
wdNY2
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
wdBOG[!(month(wdBOG)==12 & day(wdBOG)==31)]
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
ceiling
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
ColumnasIncluidas=sapply(DiasVencimiento,function(x){which(x>=MatrizDias[,1] & x<=MatrizDias[,2])})
ColumnasIncluidas
MatrizDias
DiasVencimiento
length(DiasVencimiento)
length(ColumnasIncluidas)
CoberturasGirosTot
DiasVencimiento
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
pmax(runif(10,5,10))
pmax(runif(10,5,10),0)
pmax(runif(10,5,10),10)
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
shiny::runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
shiny::runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
load("C:/Users/USUARIO/Dropbox (Quantil)/Home Center/Funciones AG/Matriz_simulaciones_final.Rdata")
dim(Simulaciones)
Simulaciones=Simulaciones[[1]]
dim(Simulaciones)
load("C:/Users/USUARIO/Dropbox (Quantil)/Home Center/Funciones AG/Matriz_simulaciones_final.Rdata")
Matriz_simulaciones=Matriz_simulaciones[[1]]
Simulaciones=Matriz_simulaciones
dimnames(Simulaciones)
Simulaciones[,c("CPICOP","BANREP","LIBOR_0.25"),]
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
rm(list=ls())
path="C:\\Users\\Andres\\Desktop\\U\\Quantil\\Dropbox (Quantil)\\DiNissan\\"
setwd(path)
# library(xlsx)
library(RQuantLib)
library(tcltk)
library(timeSeries)
library(stats)
library(mgcv)
library(fields)
library(reshape2)
library(lattice)
library(scales)
library(readxl)
vol = read.csv(".\\Datos\\Opciones\\Call.csv",check.names = F)
volput = read.csv(".\\Datos\\Opciones\\Put.csv",check.names = F)
# head(vol)
Forwards=read.csv(".\\Datos\\Opciones\\Forwads.csv",check.names=F)
rownames(Forwards)=as.character(as.Date(Forwards[,1],format="%d/%m/%Y"))
Spot=as.data.frame(Forwards[,2:3])
Forwards=Forwards[,-c(1,2)]
Forwards2=apply(Forwards,2,as.character)
Forwards2=apply(Forwards2,2,as.numeric)
rownames(Forwards2)=rownames(Forwards)
Forwards=Forwards2
vol[,1]=as.Date(vol[,1],format="%d/%m/%Y")
volput[,1]=as.Date(volput[,1],format="%d/%m/%Y")
Optimizar=function(x,maturity,underlying,volatility,delta){
A=EuropeanOption(type="call",strike=x,riskFreeRate=0,maturity=maturity,underlying=underlying,dividendYield=0,volatility=volatility/100)$delta
return((A-delta)^2)
}
StrikesCall=sapply(vol[,1],function(y){
Fecha=y
IndicadorFila=max(which(vol[,1]<=Fecha))
VolImpl=vol[IndicadorFila,-1]
rownames(VolImpl)=vol[IndicadorFila,1]
VolImpl2=cbind(t(VolImpl[,1:6]),t(VolImpl[,7:12]),t(VolImpl[,13:18]))
rownames(VolImpl2)=c(paste(c(1,2,3,6,9,12),"M",sep=""))
colnames(VolImpl2)=c("ATM","25D","10D")
IndicadorFila=max(which(as.Date(rownames(Forwards))<=Fecha))
Forwards2=Forwards[IndicadorFila,]
if(rownames(Forwards)[IndicadorFila]!=rownames(VolImpl)){
tkmessageBox(title="Error en fechas",message="Las fechas de los forwards y de las opciones son diferentes",type="ok")
}
B=NULL
for(i in 1:length(Forwards2)){
volatility=VolImpl2[i,2]
maturity=as.numeric(gsub("M","",names(Forwards2)[i]))/12
underlying=Forwards2[i]
B=c(B,optim(par=Forwards2[i],fn=Optimizar,method="L-BFGS-B",lower=1000,upper=10000,maturity=maturity,volatility=volatility,underlying=underlying,delta=0.25,control=list(parscale=100))$par)
}
C=NULL
for(i in 1:length(Forwards2)){
volatility=VolImpl2[i,3]
maturity=as.numeric(gsub("M","",names(Forwards2)[i]))/12
underlying=Forwards2[i]
C=c(C,optim(par=Forwards2[i],fn=Optimizar,method="L-BFGS-B",lower=1000,upper=10000,maturity=maturity,volatility=volatility,underlying=underlying,delta=0.1,control=list(parscale=100))$par)
}
A=cbind(t(Forwards2),t(B),t(C))
print(y)
return(A)
})
StrikesCall=t(StrikesCall)
colnames(StrikesCall)=paste(sort(rep(c("ATM","25D","10D"),6),decreasing=T),colnames(Forwards),sep=" ")
rownames(StrikesCall)=as.character(vol[,1])
tail((StrikesCall))
write.csv(StrikesCall,".\\Output\\StrikesCall.csv")
write.csv(Forwards[as.character(vol[,1]),-ncol(Forwards)],".\\Output\\Forwards.csv")
write.csv(vol,".\\Output\\VolatilidadesCall.csv",row.names=F)
Optimizar=function(x,maturity,underlying,volatility,delta){
A=EuropeanOption(type="put",strike=x,riskFreeRate=0,maturity=maturity,underlying=underlying,dividendYield=0,volatility=volatility/100)$delta
return((A-delta)^2)
}
StrikesPut=sapply(volput[,1],function(y){
Fecha=y
IndicadorFila=max(which(volput[,1]<=Fecha))
VolImpl=volput[IndicadorFila,-1]
rownames(VolImpl)=volput[IndicadorFila,1]
VolImpl2=cbind(t(VolImpl[,1:6]),t(VolImpl[,7:12]),t(VolImpl[,13:18]))
rownames(VolImpl2)=c(paste(c(1,2,3,6,9,12),"M",sep=""))
colnames(VolImpl2)=c("ATM","25D","10D")
IndicadorFila=max(which(as.Date(rownames(Forwards))<=Fecha))
Forwards2=Forwards[IndicadorFila,]
if(rownames(Forwards)[IndicadorFila]!=rownames(VolImpl)){
tkmessageBox(title="Error en fechas",message="Las fechas de los forwards y de las opciones son diferentes",type="ok")
}
B=NULL
for(i in 1:length(Forwards2)){
volatility=VolImpl2[i,2]
maturity=as.numeric(gsub("M","",names(Forwards2)[i]))/12
underlying=Forwards2[i]
B=c(B,optim(par=Forwards2[i],fn=Optimizar,method="L-BFGS-B",lower=1000,upper=10000,maturity=maturity,volatility=volatility,underlying=underlying,delta=0.25,control=list(parscale=100))$par)
}
C=NULL
for(i in 1:length(Forwards2)){
volatility=VolImpl2[i,3]
maturity=as.numeric(gsub("M","",names(Forwards2)[i]))/12
underlying=Forwards2[i]
C=c(C,optim(par=Forwards2[i],fn=Optimizar,method="L-BFGS-B",lower=1000,upper=10000,maturity=maturity,volatility=volatility,underlying=underlying,delta=0.1,control=list(parscale=100))$par)
}
A=cbind(t(Forwards2),t(B),t(C))
print(y)
return(A)
})
StrikesPut=t(StrikesPut)
colnames(StrikesPut)=paste(sort(rep(c("ATM","25D","10D"),6),decreasing=T),colnames(Forwards),sep=" ")
rownames(StrikesPut)=as.character(vol[,1])
tail((StrikesPut))
#####################################################################################################
##################################### Superficie de volatilidad #####################################
#####################################################################################################
Fecha=as.Date("2019-09-30") # as.Date("2019-07-31") # vol[nrow(vol),1]
Strikes_superficie=t(t(StrikesCall[as.character(Fecha),]))
Strikes_superficie=rbind(Strikes_superficie,t(t(StrikesPut[as.character(Fecha),-grep("ATM",colnames(StrikesPut))])))
IndicadorFila=max(which(vol[,1]<=Fecha))
VolImpl=unlist(cbind(vol[IndicadorFila,-1],volput[IndicadorFila,-c(1,1+grep("ATM",colnames(StrikesPut)))]))
VolImpl=(t(VolImpl))
Spot=Spot[as.character(Fecha),1]
# Time
xx = (rep(c(1,2,3,6,9,12),5)/12)
# Strike
yy = c(Strikes_superficie)
# ImpVol
zz = c(VolImpl)/100
#########
b1 = gam(zz ~ s(xx,yy,k=15), familiy=gaussian())
yss = seq(min(Strikes_superficie), max(Strikes_superficie), length.out=250)
xss = seq(0,1,length.out=250)
gg = expand.grid(xx=xss,yy=yss)
rr = predict.gam(b1,newdata=gg )
gg2 = cbind(gg,rr)
mama = xtabs(rr~xx+yy, data=gg2)
obj11 = list( x=  sort(unique(gg2[,2])),y=sort(unique(gg2[,1])),z=t(mama))
image.plot(obj11,ylab="Expiración (años)", xlab="Strike", main="Superficie de volatilidad")
points(yy,xx, pch=18, cex=0.75)
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
shiny::runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
runApp()
runApp('C:/Users/USUARIO/Dropbox (Quantil)/Home Center/homecenter/Shiny/QuantRisk/inst/application')
grep("hola",c("hola$1","1$hola","hola$2"))
grep("hola",c("hola$1","1$hola","hola$2"))
grep("hola$",c("hola$1","1$hola","hola$2"))
x=runif(1000,-10,10)
y=x^2
cor(x,y,method = "kendall")
cor(x,y,method = "spearman")
cor(x,y,method = "pearson")
install_github("ProcessMiner/nlcor")
library(devtools)
install.packages(devtools)
install.packages("devtools")
library(devtools)
install_github("ProcessMiner/nlcor")
library(nlcor)
nlcor(x,y)
modelito=nlcor(x,y)
print(modelito$cor.plot)
modelito=nlcor(x,y,plt = T)
print(modelito$cor.plot)
library(ggplot2)
modelito=nlcor(x,y,plt = T)
print(modelito$cor.plot)
modelito=nlcor(x,y,refine = 5,plt = T)
print(modelito$cor.plot)
x=runif(1000,-10,10)
y=x^2
cor(x,y,method = "pearson")
cor.test(x,y)
cor(x,y,method = "pearson")
nlcor(x,y,refine = 5,plt = T)$cor.estimate
modelito=nlcor(x,y,refine = 1,plt = T)
print(modelito$cor.plot)
print(modelito$cor.plot)
cor(x,y,method = "pearson")
cor(x,y,method = "kendall")
cor(x,y,method = "pearson")
nlcor(x,y,plt = T)$cor.estimate
x=runif(1000,-10,10)
y=x^2
x_unif=punif(x,min = -10, max=10)
x_unif
hist(punif(x,)
hist(punif(y))
hist((y))
x=runif(1000,-10,10)
y=runif(1000,-10,10)
x=mvtnorm::rmvnorm(1000,c(0,0),sigma = matrix(c(1,0.5,0.5,1),ncol=2))
y=x[,2]
x=x[,1]
plot(x,y)
x_unif=pnorm(x,mean =  0 ,sd = 1)
y_unif=pnorm(y,mean =  0 ,sd = 1)
plot(x_unif,y_unif)
plot(x_unif,y_unif)
cor(x_unif,y_unif)
??copula
install.packages(c("BLCOP", "fPortfolio", "LowRankQP", "pastecs"))
install.packages(c("copula", "fitdistrplus", "moments", "nortest"))
library(copula)
gC.f <- normalCopula(dim=2)
gcF.ml  <- fitCopula(gC.f, cbind(x_unif,y_unif), method="ml")
coef.t=summary(gcF.ml)$coefficients[,1]
tC.f.post <- tCopula(param=coef.t,dim=ncol(rets_aux))
tC.f.post <- tCopula(param=coef.t,dim=2)
pvars<-rCopula(n=nSim,tC.f.post)
pvars<-rCopula(n=1000,tC.f.post)
plot(pvars)
DatosFin=cbind(pnorm(pvars[,1],mean =  0 ,sd = 1),pnorm(pvars[,2],mean =  0 ,sd = 1))
plot(DatosFin)
DatosFin=cbind(qnorm(pvars[,1],mean =  0 ,sd = 1),qnorm(pvars[,2],mean =  0 ,sd = 1))
plot(DatosFin)
plot(cbind(x,y))
plot(DatosFin)
par(new=T)
plot(cbind(x,y),col="blue")
plot(DatosFin,xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
par(new=T)
plot(cbind(x,y),col="blue",xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
DatosFin=cbind(qnorm(pvars[,1],mean =  0 ,sd = 1),qnorm(pvars[,2],mean =  0 ,sd = 1))
plot(DatosFin,col="blue",xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
par(new=T)
plot(cbind(x,y),xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
plot(cbind(x,y),xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
par(new=T)
plot(DatosFin,col="blue",xlab="X",ylab="Y",xlim=range(c(DatosFin[,1],x)),ylim=range(c(DatosFin[,2],y)))
plot(pvars)
plot(pvars,xlab="X sim uniforme",ylab="Y sim uniforme")
plot(pvars,xlab="X sim uniforme",ylab="Y sim uniforme",col="blue")
CalcularMejor=function(Retornosaux,indicesTrain=NULL,j=NULL){
#######----------- Paso 1: Estimación de Distribuciones ----------- ########
Retornosaux = Retornos
#### --------- Pruebas de distancia de Kolmogorov-Smirnov ------- #######
######### ---------- Se crea una Matriz con 6 columnas (distribuciones)
######### ---------- 10 filas (Acciones)
Testkol=as.data.frame(matrix(0,ncol=5,nrow=ncol(Retornosaux)))
####### ------------ Muestra de entrenamiento/ Muestra Prueba --------- #######
porcentajeTrain=0.5
indicesTrain_aux=sample(1:(nrow(Retornosaux)),porcentajeTrain*nrow(Retornosaux))
######### ------------- Separacion entre muestra de entrenamiento y muestra de prueba ------- ########
indicesTest_aux=(1:nrow(Retornosaux))[-indicesTrain_aux]
rownames(Testkol)=colnames(Retornosaux)
#####---------- Distribuciones a estimar -------------- #######
colnames(Testkol)=c("Normal","Logistica","Uniforme","Hiperbolica","Ganador")
##### ---------- Fin construcción tabla ------ #########
retsAcc = Retornosaux
for (i in 1:ncol(Retornosaux)){
x=retsAcc[,i]
#   descdist(c(x),discrete=F)
####### --------- Ajustar un modelo Arima para definir en un GARCH--------- #####
ARMA=auto.arima(x)
AR=length(grep("ar",names(ARMA$coef)))
MA=length(grep("ma",names(ARMA$coef)))
if(AR+MA==0){
AR=1
}
##### -------- Definir el número de grados de ARCH a partir de los residuales -------- ######
## A a partir de los residuales al cuadrado se determina el grado del modelo ARCH.
#### --------- Auto
ARCH=auto.arima(ARMA$residuals^2)$coef
AR_ARCH=length(grep("ar",names(ARCH)))
MA_ARCH=length(grep("ma",names(ARCH)))
####### --------- Especificación GARCH ------- ##########
Especificacion_garch=ugarchspec(mean.model = list(armaOrder = c(AR,MA)),variance.model = list(garchOrder = c(max(1,AR_ARCH),MA_ARCH)), distribution.model = "norm")
####### ---------- Ajustar el modelo ------- ######
Garch_ajustado = ugarchfit(Especificacion_garch, data = x,solver="gosolnp")
Residuales_garch = residuals(Garch_ajustado)
xyz=as.numeric(Residuales_garch)
set.seed(124)
indicesTrain=NULL
############# --------- Definicion de entrenamiento/prueba -----#######
indicesTrain=sample(1:(length(xyz)),0.5*length(xyz))
indicesTest=(1:length(xyz))[-indicesTrain]
################ -------------- Normal: (Prueba+Entrenamiento)/2 --------------#########
######### ----------- Sobre la muestra de entrenamiento --------- #########
param_norm=try(unlist(fitdistrplus::fitdist(c(xyz[indicesTrain]),"norm")[1]),silent=T)
if(class(param_norm)=="try-error"){
Testkol[i,"Normal"]=Inf
} else {
names(param_norm)=gsub("estimate.","",names(param_norm))
######## --------- Kolmogorov-Smirnov Tests --------- #########3
Testkol[i,"Normal"]=ks.test(x=xyz[indicesTest],y = "pnorm",mean = param_norm[1], sd = param_norm[2])[[1]]
}
######### ----------- Sobre la muestra de prueba --------- #########
param_norm=try(unlist(fitdistrplus::fitdist(c(xyz[-indicesTrain]),"norm")[1]),silent=T)
if(class(param_norm)=="try-error"){
Testkol[i,"Normal"]=Inf
} else {
names(param_norm)=gsub("estimate.","",names(param_norm))
#### -------- Promedio ------ ####
Testkol[i,"Normal"]=(Testkol[i,"Normal"]+ks.test(xyz[-indicesTest],"pnorm",mean = param_norm[1], sd = param_norm[2])[[1]])/2
}
################ -------------- Uniforme: (Prueba+Entrenamiento)/2 --------------#########
######### ----------- Sobre la muestra de entrenamiento --------- #########
param_unif=try(unlist(fitdistrplus::fitdist(c(x[indicesTrain]),"unif")[1]),silent=T)
if(class(param_unif)=="try-error"){
Testkol[i,"Uniforme"] = Inf
} else {
names(param_unif)=gsub("estimate.","",names(param_unif))
Testkol[i,"Uniforme"] = ks.test(xyz[-indicesTrain],"punif",min=param_unif["min"],max=param_unif["max"])[[1]]
}
######### ----------- Sobre la muestra de prueba --------- #########
param_unif=try(unlist(fitdistrplus::fitdist(c(x[-indicesTrain]),"unif")[1]),silent=T)
if(class(param_unif)=="try-error"){
Testkol[i,"Uniforme"]=Inf
} else {
names(param_unif)=gsub("estimate.","",names(param_unif))
#### -------- Promedio ------ ####
Testkol[i,"Uniforme"]=(Testkol[i,"Uniforme"]+ks.test(xyz[indicesTrain],"punif",min=param_unif["min"],max=param_unif["max"])[[1]])/2
}
################ -------------- Logistica: (Prueba+Entrenamiento)/2 --------------#########
######### ----------- Sobre la muestra de entrenamiento --------- #########
param_logistic=try(unlist(fitdistrplus::fitdist(c(xyz[indicesTrain]),"logis")[1]),silent=T)
if (class(param_logistic)=="try-error"){
Testkol[i,"Logistica"]= Inf
} else {
names(param_logistic)=gsub("estimate.","",names(param_logistic))
Testkol[i,"Logistica"]=ks.test(xyz[-indicesTrain],"plogis",location = param_logistic[1], scale = param_logistic[2])[[1]]
}
######### ----------- Sobre la muestra de prueba --------- #########
param_logistic=try(unlist(fitdistrplus::fitdist(c(xyz[-indicesTrain]),"logis")[1]),silent=T)
if(class(param_logistic)=="try-error"){
Testkol[i,"Logistica"]=Inf
} else {
names(param_logistic)=gsub("estimate.","",names(param_logistic))
Testkol[i,"Logistica"]=(Testkol[i,"Logistica"]+ks.test(xyz[indicesTrain],"plogis",location = param_logistic[1], scale = param_logistic[2])[[1]])/2
}
################ -------------- Hiperbolica: (Prueba+Entrenamiento)/2 --------------#########
param_hyper=try(unlist(ghFit(c(xyz[indicesTrain]),trace=F,doplot=F)@fit$estimate),silent=T)
######### ----------- Sobre la muestra de entrenamiento --------- #########
if(class(param_hyper)=="try-error"){
Testkol[i,"Hiperbolica"]=Inf
} else {
names(param_hyper)=gsub("estimate.","",names(param_hyper))
Testkol[i,"Hiperbolica"]=ks.test(xyz[-indicesTrain],"pgh",alpha=param_hyper["alpha"],beta=param_hyper["beta"],delta=param_hyper["delta"],mu=param_hyper["mu"],lambda=param_hyper["lambda"])[[1]]
}
######### ----------- Sobre la muestra de prueba --------- #########
param_hyper=try(unlist(ghFit(c(xyz[-indicesTrain]),trace=F,doplot=F)@fit$estimate),silent=T)
if(class(param_hyper)=="try-error"){
Testkol[i,"Hiperbolica"]= Inf
} else {
names(param_hyper)=gsub("estimate.","",names(param_hyper))
Testkol[i,"Hiperbolica"]=(Testkol[i,"Hiperbolica"]+ks.test(xyz[indicesTrain],"pgh",alpha=param_hyper["alpha"],beta=param_hyper["beta"],delta=param_hyper["delta"],mu=param_hyper["mu"],lambda=param_hyper["lambda"])[[1]])/2
}
print(i)
}
###### ----------- Las mejores marginales Independiente -------- #####
Testkol[,"Ganador"]=colnames(Testkol)[apply(Testkol[,-ncol(Testkol)],1,which.min)]
# Testkol=Testkol[,-3]
Testkol[,1:5]=round(Testkol[,1:5],4)
Testkol[Testkol==Inf]="No Convergió"
}
###### --------------------- Ejercicio: Optimizacion de portafolios ----------------- ############
####### ----------- Limpiar ambiente ------- ######
rm(list = ls())
options(scipen = 10000000)
##### --------- Path: automatico  --------- #####
path <<- gsub(rstudioapi::getActiveDocumentContext()$path,pattern = "/Script.+",replacement = "")
setwd(paste0(path))
##### -------- librerias ------- ######
librerias <- c("readxl","ggplot2","scales",'timeSeries','timeSeries','forecast','rugarch','fBasics','moments','tseries','PortfolioAnalytics','dplyr','zoo','nleqslv')
###### ----- Instalacion liberarias ------ ####
if(length(setdiff(librerias, rownames(installed.packages()))) > 0){
install.packages(setdiff(librerias, rownames(installed.packages())))}
invisible(sapply(librerias, require, character.only = TRUE,quietly = TRUE))
source('Utilities.R',)
##### --------- Paso 1: Cargar datos ------ #####
TESCOP = read_excel('Datos/TESCOP.xlsx')
TESCOP= as.data.frame(TESCOP)
############ ---------- Ejemplo de la construcción de un índice entre dos TES -------- ######
####### ---------- Funcion TES ----------- ######
rownames(TESCOP) = as.Date(TESCOP[,1])
TESCOP = TESCOP[,-1]
colnames(TESCOP) = gsub(x = colnames(TESCOP),pattern = 'TESCOP_',replacement = '')
##### ------- Se toman los Meses y se pasan a numero ---- #####
colnames(TESCOP)[grep(colnames(TESCOP),pattern = 'M')] = as.numeric(gsub(colnames(TESCOP)[grep(colnames(TESCOP),pattern = 'M')],pattern = 'M',replacement = ''))/12
##### ------- Se toman los años y se pasan a numero---- #####
colnames(TESCOP)[grep(colnames(TESCOP),pattern = 'Y')] = as.numeric(gsub(colnames(TESCOP)[grep(colnames(TESCOP),pattern = 'Y')],pattern = 'Y',replacement = ''))
######## ---- Interpolacion de un nodo de 10 - semana ------ ###
Interpolacion = apply(TESCOP, 1, function(z){approx(x = as.numeric(colnames(TESCOP)),y = as.numeric(z),xout = ((365*10-7)/365))$y})
TESCOP[,'9.98'] = Interpolacion
############ -------- Semanalizar: Cogiendo ---------- ##########
## Vamos a generar la serie semanal ##
DatosSem=seq(as.Date(rownames(TESCOP)[1]),as.Date(tail(rownames(TESCOP),1)),by = "week")
## En caso de festivos, tomamos el dia mas cercano.
DatosSem=sapply(DatosSem,function(x){which.min(abs(as.Date(rownames(TESCOP))-x))})
######## --------- Consolidar DataFrame: Resultados -------- ######
TESCOP = TESCOP[c(DatosSem),]
Resultados = data.frame('Semana'=c(1:dim(TESCOP)[1]),'Tasa1'=TESCOP[,'10'],'Tasa2'=TESCOP[,'9.98'],'TES1'=0,'TES2'=0)
####### ------- Rendimientos ------ ######
for (j in c(1:dim(Resultados)[1])) {
##### ---- TES 1 ---- ###
Resultados[j,"TES1"] = 1/(1+(Resultados[j,"Tasa1"]/100))^(10)
##### ---- TES 2 ---- ###
Resultados[j,"TES2"] = 1/(1+(Resultados[j,"Tasa2"]/100))^((365*10-7)/365)
}
TESS = cbind(Resultados[-nrow(Resultados),"TES1"],Resultados[-1,"TES2"])
Resultados$Acum = c(1,cumprod(TESS[,2]/TESS[,1]))
returns(Resultados)
dim(Resultados)
head(Resultados)
source('C:/Users/USUARIO/Dropbox (Quantil)/Uniandes Portafolio/Clases/Clase 7 - Ejercicio/Ejercicios/CalcularMejor.R', encoding = 'UTF-8')
source('C:/Users/USUARIO/Dropbox (Quantil)/Uniandes Portafolio/Clases/Clase 7 - Ejercicio/Ejercicios/Utilities.R', encoding = 'UTF-8')
library(kernlab)
